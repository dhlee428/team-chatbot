{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b61d369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "\n",
    "openai_embedding=OpenAIEmbeddings(model = 'text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "264b1c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_pdf(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    return loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68da13bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    split_docs = text_splitter.split_documents(_docs)\n",
    "    persist_directory = \"./chroma_db\"\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        split_docs, \n",
    "        OpenAIEmbeddings(model='text-embedding-3-small'),\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee31e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_vector_store(new_docs, persist_directory=\"./chroma_db\"):\n",
    "    # 1. 기존 벡터 저장소 불러오기\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    )\n",
    "\n",
    "    # 2. 문서 분할\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    split_docs = text_splitter.split_documents(new_docs)\n",
    "\n",
    "    # 3. 문서 추가\n",
    "    vectorstore.add_documents(split_docs)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26c04695",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../하지환교수님'\n",
    "pl=os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "402e809b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x298fb46fc10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk=load_and_split_pdf(os.path.join(path, pl[0]))\n",
    "create_vector_store(mk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8daf25fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9000\\3363452400.py:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "for i in pl[1:]:\n",
    "    ad=load_and_split_pdf(os.path.join(path, i))\n",
    "    add_to_vector_store(ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb6f8af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manuscript received 12 December 2020; revised 16 May 2022; accepted 8 July\n",
      "2022. Date of publication 18 July 2022; date of current version 3 April 2023.\n",
      "This work was supported by the Institute of Information & Communications\n",
      "Technology Planning & Evaluation (IITP), funded by the Korean Government,\n",
      "MSIT, under Grant IITP-2017-0-00477, (SW starlab) Research and develop-\n",
      "ment of the high performance in-memory distributed DBMS based on ﬂash\n",
      "memory storage in an IoT environment.\n",
      "(Corresponding author: Sanghyun Park.)\n",
      "Digital Object Identiﬁer no. 10.1109/TCBB.2022.3191972\n",
      "IEEE/ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS, VOL. 20, NO. 2, MARCH/APRIL 2023 1257\n",
      "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n"
     ]
    }
   ],
   "source": [
    "# load from disk\n",
    "db3 = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "query = \"HyungBin Moon's 2021 paper?\"\n",
    "result = db3.similarity_search(query)\n",
    "print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09418cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9000\\3330118453.py:19: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-4o\")\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9000\\3330118453.py:20: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=PROMPT)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9000\\3330118453.py:22: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  summary = chain.run(context=context_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**연구대상 및 방법:**\n",
      "이 연구는 miRNA(마이크로 리보핵산)와 질병 간의 연관성을 예측하는 것을 목표로 합니다. 연구 대상은 다양한 생물학적 데이터를 활용하여 miRNA-질병 연관성을 분석하는 것이며, 이를 통해 miRNA가 질병에 미치는 영향을 이해하고자 합니다.\n",
      "\n",
      "**연구방법:**\n",
      "연구에서는 기계 학습과 데이터 마이닝 기법을 사용하여 miRNA-질병 연관성을 예측합니다. 구체적으로, 그래프 컨볼루션 네트워크(Graph Convolutional Network, GCN)와 신경 협업 필터링(Neural Collaborative Filtering)을 결합하여 miRNA와 질병 간의 연관성을 모델링합니다. 또한, 네트워크 거리 분석 및 행렬 분해(Matrix Factorization) 기법을 활용하여 질병 유사성 제약을 고려한 모델을 설계합니다.\n",
      "\n",
      "**연구결과:**\n",
      "연구 결과, 제안된 방법론이 miRNA-질병 연관성을 예측하는 데 있어 높은 성능을 보였습니다. Kaplan-Meier 생존 분석을 통해 특정 miRNA(hsa-miR-148a, hsa-miR-133b 등)가 유방암 환자의 생존율에 미치는 영향을 시각화하였으며, IMIPMF를 사용하여 학습된 잠재 벡터를 통해 miRNA의 역할을 효과적으로 분석할 수 있음을 보였습니다.\n",
      "\n",
      "**제언:**\n",
      "본 연구는 miRNA-질병 연관성 예측의 정확성을 높이기 위해 다양한 생물학적 데이터의 의미 있는 특징을 추출할 필요성을 제안합니다. 향후 연구에서는 새로운 기계 학습 기법과 데이터 통합 방법을 개발하여 miRNA와 질병 간의 복잡한 상호작용을 더욱 정교하게 분석할 것을 권장합니다. 이러한 접근은 궁극적으로 개인화된 의학 및 정밀 의학 발전에 기여할 수 있을 것입니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "db3 = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "query = \"explain jiwhan Ha's 2020 paper\"\n",
    "docs = db3.similarity_search(query, k=15)\n",
    "\n",
    "formatted_docs = [Document(page_content=doc.page_content) for doc in docs]\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "다음은 논문 일부입니다. 이 내용을 바탕으로 석사 논문 내용을 연구대상 및 방법, 연구방법, 연구결과, 제언을 핵심적으로 요약해 주세요.\n",
    "논문 내용:\n",
    "{context}\n",
    "요약:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\"])\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)\n",
    "context_text = \"\\n\\n\".join([doc.page_content for doc in formatted_docs])\n",
    "summary = chain.run(context=context_text)\n",
    "print(summary, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
