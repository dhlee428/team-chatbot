{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b61d369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "openai_embedding=OpenAIEmbeddings(model = 'text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "264b1c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_pdf(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    return loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68da13bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    split_docs = text_splitter.split_documents(_docs)\n",
    "    persist_directory = \"./chroma_db\"\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        split_docs, \n",
    "        OpenAIEmbeddings(model='text-embedding-3-small'),\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee31e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_vector_store(new_docs, persist_directory=\"./chroma_db\"):\n",
    "    # 1. 기존 벡터 저장소 불러오기\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    )\n",
    "\n",
    "    # 2. 문서 분할\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    split_docs = text_splitter.split_documents(new_docs)\n",
    "\n",
    "    # 3. 문서 추가\n",
    "    vectorstore.add_documents(split_docs)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "402e809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path3='C:/python workspace/3-3/챗봇/논문/지준화_학위.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8daf25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp3=load_and_split_pdf(path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "998446b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x1c1ea264550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_to_vector_store(sp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb6f8af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This certifies that the master thesis of \n",
      "Jihwan Ha is approved. \n",
      " \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "The Graduate School \n",
      "Yonsei University \n",
      "July 2015\n"
     ]
    }
   ],
   "source": [
    "# load from disk\n",
    "db3 = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "query = \"topic of jihwan Ha\"\n",
    "result = db3.similarity_search(query)\n",
    "print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b6292a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ii \n",
      " \n",
      "제품유형별 소비자 정보탐색 행동 분석 \n",
      ": 탐색재와 경험재를 중심으로 \n",
      "Analysis on Consumer Information Search Behavior  \n",
      "for Search and Experience Goods \n",
      " \n",
      "지도교수 이 종 수  \n",
      " \n",
      "이 논문을 공학석사학위 논문으로 제출함  \n",
      " \n",
      "2014 년 2 월  \n",
      " \n",
      "서울대학교 대학원  \n",
      "협동과정 기술경영경제정책전공  \n",
      "문     형     빈  \n",
      " \n",
      "문형빈의 공학석사학위 논문을 인준함  \n",
      "2014 년 2 월  \n",
      " \n",
      "위 원 장       박  하  영      (인) \n",
      "부위원장       이  종  수      (인) \n",
      "위    원       이  정  동      (인)\n"
     ]
    }
   ],
   "source": [
    "query = \"문형빈 교수님 석사 논문 요약해줘\"\n",
    "result = db3.similarity_search(query)\n",
    "print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08d42616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 66 -\n",
      "감사의 글\n",
      "약간의 시행착오 끝에 조금 늦게 들어온 2년간의 대학원 생활을 돌이켜 한\n",
      "편의 논문으로 대신하기엔 아쉬움이 많이 남지만, 모교인 인하대학교에서 대학\n",
      "원 생활을 잘 마무리할 수 있게 되어서 뜻 깊게 생각합니다. 이 논문이 완성되\n",
      "기까지 저를 도와주시고 지도해 주신 분들에게 감사의 마음을 전하고자 합니다.\n",
      "우선 학부 때부터 대학원 생활까지 부족했던 저를 지도해주시고, 학문뿐만 아\n",
      "니라 인격적으로도 항상 아낌없는 가르침을 주신 이규성 교수님께 진심으로 감\n",
      "사의 마음을 전합니다. 언제 어디에서나 교수님의 가르침을 잊지 않는 제자가\n",
      "되도록 노력하겠습니다. 또한 미흡한 저의 논문을 심사해주신 김병국 교수님과\n",
      "김태정 교수님께도 감사를 드립니다. 그밖에 학부 때부터 대학원에 이르기까지\n",
      "지리정보공학이라는 학문에 대해 많은 가르침을 주신 조동행, 김계현, 박수홍,\n",
      "박관동 교수님께 머리 숙여 감사드립니다.\n",
      "원격탐사연구실의 든든한 버팀목 정숙이 누나, 꼼꼼한 여상이 형 미국 가서도\n",
      "건강하게 공부 마치시길 바랍니다. 웃는 얼굴이 예쁜 선화 누나, 늘 고생하는\n",
      "성진이 형 남은 대학원 생활 건투를 빕니다. 항상 옆에서 많이 가르쳐 주고 여\n",
      "러 가지 도움을 많이 준 정일이 형께도 고마움을 전합니다. 타국에서 공부하느\n",
      "라 고생이 많은 야써도 좋은 결과 있기를 바란다.\n",
      "2년간 삭막할 것만 같던 대학원 생활을 즐겁게 보낼 수 있게 해준 영상공학\n",
      "연구실의 태윤이 형, 수암이 형, 동욱이, 재훈이, 대전서 고생하는 베프(?) 현숙\n",
      "이, GIS연구실의 철용이, 은지, 태훈이, GPS연구실의 지현이, 경희, 지혜, 혜인\n",
      "이, 그리고 동기 진아 형과 이 밖의 모든 지리정보공학과 대학원생 선후배분들\n",
      "에게 감사의 마음을 전합니다.\n",
      "바쁘다는 핑계로 자주 못 만난 11대 지리정보공학과 학생회 enJoin의 필모,\n",
      "현민, 재묵, 진근, 삼화, 경수, 승호, 동현, 태윤아 앞으로 번개 꼭 나갈 테니 꼭\n",
      "불러줘. 지금은 뿔뿔이 흩어졌지만 현석이, 종민이, 철희 힘내서 잘 살아보자.\n"
     ]
    }
   ],
   "source": [
    "query = \"지준화 교수님 석사 논문 요약해줘\"\n",
    "result = db3.similarity_search(query)\n",
    "print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09418cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**연구대상 및 방법:**\n",
      "이 연구는 KOMPSAT-2 고해상도 위성영상의 절대복사보정과 검증을 목적으로 한다. 연구는 위성영상의 복사보정 계수를 추정하고, 이 계수의 적합성을 다양한 방법으로 분석하여 검증하는 것을 목표로 한다. \n",
      "\n",
      "**연구방법:**\n",
      "연구에서는 복사에너지 기반의 비교와 반사율 기반의 비교를 통해 절대복사보정 계수의 적합성을 분석하였다. 이는 타 위성 자료와의 복사에너지 및 반사율을 비교하고, 영상과 현지에서 측정한 반사율을 비교하는 방식으로 진행되었다.\n",
      "\n",
      "**연구결과:**\n",
      "연구 결과, 추정된 절대복사보정 계수는 타 위성 자료와의 복사에너지 및 반사율 비교에서 높은 적합성을 보였다. 영상과 현지 측정 반사율 비교에서도 일관된 결과가 나타나, 계수의 신뢰성을 확인할 수 있었다.\n",
      "\n",
      "**제언:**\n",
      "추후 연구에서는 다양한 위성 데이터를 활용한 추가적인 검증을 통해 복사보정 계수의 정확성을 더욱 높일 필요가 있다. 또한, 다양한 환경 조건에서의 데이터 수집 및 분석을 통해 계수의 적용 범위를 확장하는 것이 바람직하다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "db3 = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "query = \"지준화 교수님의 석사 논문 요약해줘\"\n",
    "docs = db3.similarity_search(query, k=15)\n",
    "\n",
    "formatted_docs = [Document(page_content=doc.page_content) for doc in docs]\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "다음은 논문 일부입니다. 이 내용을 바탕으로 석사 논문 내용을 연구대상 및 방법, 연구방법, 연구결과, 제언을 핵심적으로 요약해 주세요.\n",
    "논문 내용:\n",
    "{context}\n",
    "요약:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\"])\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)\n",
    "context_text = \"\\n\\n\".join([doc.page_content for doc in formatted_docs])\n",
    "summary = chain.run(context=context_text)\n",
    "print(summary, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8d28f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**연구대상 및 방법:**\n",
      "이 연구는 질병과 관련된 microRNAs(miRNAs)를 환경 요인 기반의 글로벌 miRNA 네트워크를 통해 추출하는 방법을 제안합니다. 연구대상은 다양한 질병의 발생에 관여하는 것으로 알려진 miRNAs로, 이들의 네트워크를 분석하여 질병과의 관계를 파악하려는 것입니다.\n",
      "\n",
      "**연구방법:**\n",
      "본 연구는 miRNAs와 질병 간의 관계를 규명하기 위해 환경 요인(Environmental Factor, EF) 데이터를 miRNA 글로벌 네트워크에 결합하였습니다. 환경 요인에는 방사선, 약물, 바이러스, 알코올, 담배, 스트레스 등이 포함됩니다. 모든 miRNA 쌍 간의 상호작용을 고려한 글로벌 네트워크를 구축하여 정밀한 분석을 수행하였습니다.\n",
      "\n",
      "**연구결과:**\n",
      "miRNAs와 환경 요인 간의 관계가 질병 유형을 분류하는 데 중요한 역할을 한다는 연구 결과가 증가하고 있습니다. 이 연구는 이러한 관계를 활용하여 질병과 관련된 miRNAs를 보다 정확하게 추출할 수 있음을 보여줍니다.\n",
      "\n",
      "**제언:**\n",
      "본 연구는 제한된 miRNA와 질병 간의 지식을 확장하는 데 기여하며, 미래 연구자들에게는 miRNA와 환경 요인의 상호작용을 더 깊이 탐구할 것을 권장합니다. 추가적으로, 이 연구에서 제안된 모델은 시장 예측을 보다 정밀하게 수행할 수 있는 틀을 제공합니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "db3 = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "query = \"ha jihwan's thesis summary\"\n",
    "docs = db3.similarity_search(query, k=15)\n",
    "\n",
    "formatted_docs = [Document(page_content=doc.page_content) for doc in docs]\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "다음은 논문 일부입니다. 이 내용을 바탕으로 석사 논문 내용을 연구대상 및 방법, 연구방법, 연구결과, 제언을 핵심적으로 요약해 주세요.\n",
    "논문 내용:\n",
    "{context}\n",
    "요약:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\"])\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)\n",
    "context_text = \"\\n\\n\".join([doc.page_content for doc in formatted_docs])\n",
    "summary = chain.run(context=context_text)\n",
    "print(summary, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16790df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**연구대상 및 방법:**\n",
      "이 연구는 소비자들이 제품을 구매할 때 탐색재(search goods)와 경험재(experience goods)로 구분하여 정보탐색 행동을 분석하는 것을 목적으로 한다. 탐색재는 구매 전 충분한 정보를 수집하여 품질을 평가할 수 있는 제품이며, 경험재는 직접 사용해보지 않고는 품질을 평가하기 어려운 제품이다.\n",
      "\n",
      "**연구방법:**\n",
      "연구는 설문조사를 통해 소비자들이 정보탐색을 위해 사용하는 다양한 정보채널(예: 인터넷 검색, 전문가 리뷰, 친구 추천 등)을 분석하고, 이러한 정보채널이 탐색재와 경험재 구매에 어떻게 영향을 미치는지를 실증 모형을 통해 분석하였다. 연구는 소비자 특성과 정보채널 선택 사이의 관계를 분석하기 위해 실증 모형을 활용하였다.\n",
      "\n",
      "**연구결과:**\n",
      "연구 결과, 소비자 특성에 따라 탐색재와 경험재에서 정보채널의 선택과 활용이 다르게 나타났다. 예를 들어, 탐색재의 경우 소비자들은 주로 온라인 검색을 통해 정보를 얻는 반면, 경험재에서는 친구나 전문가의 추천이 더 큰 영향을 미치는 것으로 나타났다. 또한, 특정 정보채널의 활용 빈도는 소비자의 연령, 교육 수준, 디지털 리터러시 등과 유의한 상관관계를 보였다.\n",
      "\n",
      "**제언:**\n",
      "기업들은 제품 유형에 따라 소비자들이 선호하는 정보채널을 파악하여, 그에 맞는 마케팅 전략을 수립할 필요가 있다. 특히, 경험재의 경우 소비자들이 중요하게 여기는 추천 및 리뷰 시스템을 강화하고, 탐색재에서는 온라인 정보의 질과 접근성을 높이는 것이 중요하다. 또한, 소비자 교육을 통해 보다 효율적인 정보탐색 방법을 제시할 수 있을 것이다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "db3 = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "query = \"문형빈 교수님의 석사 논문 요약해줘\"\n",
    "docs = db3.similarity_search(query, k=15)\n",
    "\n",
    "formatted_docs = [Document(page_content=doc.page_content) for doc in docs]\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "다음은 논문 일부입니다. 이 내용을 바탕으로 석사 논문 내용을 연구대상 및 방법, 연구방법, 연구결과, 제언을 핵심적으로 요약해 주세요.\n",
    "논문 내용:\n",
    "{context}\n",
    "요약:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\"])\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)\n",
    "context_text = \"\\n\\n\".join([doc.page_content for doc in formatted_docs])\n",
    "summary = chain.run(context=context_text)\n",
    "print(summary, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
